{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from os import path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = False\n",
    "import tensorflow as tf\n",
    "if gpu:\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    physical_devices = tf.config.list_physical_devices('GPU') \n",
    "    try: \n",
    "      tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
    "    except: \n",
    "      # Invalid device or cannot modify virtual devices once initialized. \n",
    "      pass # dynamically grow GPU memory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_images(basepath):\n",
    "    count = 0\n",
    "    images = glob.glob(f'{basepath}/**/*.jpg')\n",
    "    for image in images:\n",
    "        os.remove(image)\n",
    "        count += 1\n",
    "    print(\"Cleaned \", count, \" images.\")\n",
    "    audioFiles = glob.glob(f'{basepath}/**/*.wav')\n",
    "    for wav in audioFiles:\n",
    "        os.remove(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_images(\"train\")\n",
    "clean_images(\"test\")\n",
    "clean_images(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileExists(basepath, file):\n",
    "    return path.exists(f'{basepath}/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "import librosa\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def isAudioFake(basepath, fakeMP4, originalMP4):\n",
    "    if fileExists(basepath, fakeMP4) and fileExists(basepath, originalMP4):\n",
    "        fakeAudio = re.sub(r'(\\.mp4$)', '.wav', fakeMP4)\n",
    "        if not fileExists(basepath, fakeAudio):\n",
    "            !ffmpeg -i {basepath}/{fakeMP4} -ab 160k -ac 2 -ar 44100 -vn {basepath}/{fakeAudio}\n",
    "        originalAudio = re.sub(r'(\\.mp4$)', '.wav', originalMP4)\n",
    "        if not fileExists(basepath, originalAudio):\n",
    "            !ffmpeg -i {basepath}/{originalMP4} -ab 160k -ac 2 -ar 44100 -vn {basepath}/{originalAudio}\n",
    "    \n",
    "        y1, sr1 = librosa.load(f'{basepath}/{fakeAudio}')\n",
    "        y2, sr2 = librosa.load(f'{basepath}/{originalAudio}')\n",
    "        mfcc1 = librosa.feature.mfcc(y1,sr1)   #Computing MFCC values\n",
    "        mfcc2 = librosa.feature.mfcc(y2, sr2)\n",
    "        distance, path = fastdtw(mfcc1.T, mfcc2.T, dist=euclidean)\n",
    "        print(\"distance = \", distance)\n",
    "        return distance > 0\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_movie(basepath, moviePath, label, split):\n",
    "    if fileExists(basepath, moviePath):\n",
    "        print(\"Processing movie, \", moviePath, \" with label, \", label, \" and split, \", split)\n",
    "        movie = re.sub(r'(\\.mp4$)', '', moviePath)\n",
    "        !ffmpeg -i {basepath}/{moviePath} -r 1/1 {split}/{label}/{movie}%08d.jpg\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#metadataFiles = glob.glob('G:/deepfake/**/**/metadata.json')\n",
    "metadataFiles = glob.glob('movies/**/metadata.json')\n",
    "MAX_MOVIES=120\n",
    "\n",
    "moviesProcessed = 0\n",
    "testSamplingRate = 5  # every 5th movie, put into test, every sixth movie put into validation\n",
    "\n",
    "def processMetadataFile(metadataFile, moviesProcessed):\n",
    "    numRealMovies = 0\n",
    "    numFakeMovies = 0\n",
    "    numAudioFakes = 0\n",
    "    originalsProcessed = 0\n",
    "    audioFakes = []\n",
    "\n",
    "    for metadata in metadataFile:\n",
    "        basepath=re.sub(r'(metadata.json$)', '', metadata)[:-1]\n",
    "        with open(metadata) as f:        \n",
    "            data = json.load(f)\n",
    "            for key in data:\n",
    "                if moviesProcessed > MAX_MOVIES:\n",
    "                    print(\"moviesProcessed > MAX\")\n",
    "                    break\n",
    "                label = data[key]['label']\n",
    "                if moviesProcessed % testSamplingRate == 0:\n",
    "                    split = \"test\"\n",
    "                elif moviesProcessed % testSamplingRate == 1:\n",
    "                    split = \"validation\"\n",
    "                else:\n",
    "                    split = \"train\"\n",
    "                if label == \"FAKE\" and 2 * numFakeMovies > numRealMovies:\n",
    "                    print(\"Skipping because we need balanced fake and real videos\")\n",
    "                elif label == \"FAKE\":\n",
    "                    original = data[key]['original']\n",
    "                    \n",
    "                    if isAudioFake(basepath, key, original):\n",
    "                        numAudioFakes += 1\n",
    "                        audioFakes.append(f'{basepath}/{key}')\n",
    "                    else:\n",
    "                        processed = process_movie(basepath, key, label, split)\n",
    "                        moviesProcessed += processed\n",
    "                        numFakeMovies += processed\n",
    "\n",
    "                        processed = process_movie(basepath, original, \"REAL\", split)\n",
    "                        moviesProcessed += processed\n",
    "                        numRealMovies += processed\n",
    "                        originalsProcessed += processed\n",
    "\n",
    "                else:\n",
    "                    numRealMovies += 1\n",
    "                    processed = process_movie(basepath, key, label, split)\n",
    "\n",
    "                    moviesProcessed += processed\n",
    "    print(\"Processed originals\", originalsProcessed, \" videos for train.\")\n",
    "    print(\"Detected and skipped \", numAudioFakes, \" fake videos with fake audio.\")\n",
    "\n",
    "    return moviesProcessed, audioFakes\n",
    "      \n",
    "(moviesProcessed, audioFakes) = processMetadataFile(metadataFiles, moviesProcessed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processed \", moviesProcessed, \" videos for train.\")\n",
    "print(\"audioFakes are \", audioFakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detect_face import crop_face_save_jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = glob.glob('train/**/*.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the faces in each image, and crop it out\n",
    "# If the face can't be detected, then we remove the image from dataset\n",
    "for image in trainImages:\n",
    "    crop_face_save_jpg(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImages = glob.glob('test/**/*.jpg')\n",
    "for image in testImages:\n",
    "    crop_face_save_jpg(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImages = glob.glob('validation/**/*.jpg')\n",
    "for image in testImages:\n",
    "    crop_face_save_jpg(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished preprocessing movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "from pickle import dump\n",
    "\n",
    "def extract_features(filepath):\n",
    "    \"\"\"takes the cropped faces and extracts features from them. takes the file path of the face data\"\"\"\n",
    "    # load model\n",
    "    model = VGG16()\n",
    "    # remove the output layer\n",
    "    model.layers.pop()\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "    features = np.zeros((1, 4096))\n",
    "    filepath = os.path.join(filepath,'*.jpg')\n",
    "    faces = glob.glob(filepath)\n",
    "    for face in faces:\n",
    "        # load an image from file\n",
    "        image = load_img(face, target_size=(224, 224))\n",
    "        # convert the image pixels to a numpy array\n",
    "        image = img_to_array(image)\n",
    "        # reshape data for the model\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        #print(image.shape)\n",
    "        #prepare the image for the VGG model\n",
    "        image = preprocess_input(image)\n",
    "        # get extracted features\n",
    "        features = np.append(features,  model.predict(image), axis = 0)\n",
    "        #print(features.shape)\n",
    "        # save to file\n",
    "        #dump(features, f)\n",
    "    #save to pd dataframe\n",
    "    features = np.delete(features, 0, 0)\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fake_df = extract_features('train/fake/')\n",
    "train_real_df = extract_features('train/real/')\n",
    "\n",
    "test_real_df = extract_features('test/real/')\n",
    "test_fake_df = extract_features('test/fake/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_real_df = extract_features('validation/real/')\n",
    "validation_fake_df = extract_features('validation/fake/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write extracted features to disk\n",
    "train_fake_df.to_csv('train_fake.csv')\n",
    "train_real_df.to_csv('train_real.csv')\n",
    "test_fake_df.to_csv('test_fake.csv')\n",
    "test_real_df.to_csv('test_real.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_fake_df.to_csv('validation_fake.csv')\n",
    "validation_real_df.to_csv('validation_real.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers.pop()\n",
    "#model.layers.pop()\n",
    "#model.layers.pop()\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
